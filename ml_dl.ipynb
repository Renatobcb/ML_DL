{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renatobcb/ML_DL/blob/main/ml_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Um modelo de Sistema de Alerta Precoce (EWS) para crises financeiras\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "class Config:\n",
        "    \"\"\" Creates a config object that specifies how the data is processed and how the experiment is run.\n",
        "        The default values assigned here can be altered by the user in the experiment files (see experiments folder)\n",
        "     \"\"\"\n",
        "    \n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "         # Path of R is needed as the decision tree is trained in R.\n",
        "        self.r_path = None # e.g. 'C:\\\\Program Files\\\\R\\\\R-3.5.1\\\\bin\\\\x64\\\\Rscript'\n",
        "        \n",
        "        #### The following parameters determine how the data is processed ####\n",
        "        self.data_predictors = [\"drate\", \"cpi_pdiff\" , \"bmon_gdp_rdiff\", \"stock_pdiff\",\n",
        "                                 \"cons_pdiff\" ,\n",
        "                                 \"pdebt_gdp_rdiff\", \"inv_gdp_rdiff\", \"ca_gdp_rdiff\",\n",
        "                                 \"tloan_gdp_rdiff\",\n",
        "                                 \"tdbtserv_gdp_rdiff\", \"global_loan\"]  # Names of the indicators used as predictors\n",
        "        # pdiff: percentage change\n",
        "        # rdiff ratio change. Change of the variable relative to the change in GDP\n",
        "        self.data_horizon = 2  # Horizon of percentage and ratio changes (in years)\n",
        "\n",
        "        self.data_period = 'all'  # The time frame investigate. Either 'all' observations,\n",
        "        # or 'pre-ww2' or 'post-ww2'.\n",
        "        self.data_exclude_extreme_period = True  # Whether to exclude WW1, WW2 and \n",
        "        # the Great Depression\n",
        "        self.data_include_crisis_year = False  # Whether to exclude the actual crisis\n",
        "        # observation and only predict years a head of a crisis\n",
        "        self.data_years_pre_crisis = 2  # number of years before a crisis for\n",
        "        # which outcome is set positive\n",
        "        self.data_post_crisis = 4  #  How many observations (in years) after the \n",
        "        # crisis should be deleted to avoid post-crisis bias\n",
        "        \n",
        "        \n",
        "        \n",
        "        #### The following parameters determine experimental details ####\n",
        "\n",
        "        self.exp_n_kernels = 1  # The number of kernels of the CPU used in parallel\n",
        "        self.exp_nfolds = 5  # Number of folds in the cross-validation experiment.\n",
        "\n",
        "        self.exp_algos = ['extree', \"log\"]  # list of algorithms that are tested in the experiment\n",
        "\n",
        "        self.exp_year_split = None  # If 'None' the cross-validation experiment is run.\n",
        "        # If it is a year y all instances up to that year are used for training and \n",
        "        # the following observations for testing the model. The latter option is used for forecasting\n",
        "\n",
        "        self.exp_id = \"crisis\"\n",
        "        # This variable specifies constraints for the cross-validation\n",
        "        # 'no': no constraint used\n",
        "        # 'crisis': the observation of a crisis (by default 1-2 years before crisis)\n",
        "        #   are assigned to the same fold\n",
        "        # 'year': all observations of a certain year are assigned to the same fold\n",
        "        # 'year_and_crisis' combination of the two constraints above\n",
        "\n",
        "        # Hyperparameter search\n",
        "        self.exp_verbose = 0  # Determines how verbose the output of the hyperparameter search is. \n",
        "        self.exp_hyper_folds = 5  # Number of folds in the cross-validation of the hyperparameters\n",
        "        self.exp_rep_cv = 1  # How often the cross-validation of the hyperparameters is repeated.\n",
        "        self.exp_search = \"grid\"  # Either we use full 'grid' search or 'random' search\n",
        "        self.exp_n_iter_rsearch = 250  # How many hyperparamter combinations are tested in the random search\n",
        "        self.exp_optimization_metric = 'roc_auc'  # Metric that is optimized in the hyperparameter search\n",
        "\n",
        "        # Shapley\n",
        "        self.exp_do_shapley = True  # Whether Shapley values are computed\n",
        "        self.exp_shap_background = 50  # Number of background samples used by the Shapley Kernel explainer\n",
        "        self.exp_shapley_interaction = False  # Whether interactions of Shapley values are computed\n",
        "\n",
        "        self.exp_error_costs = \"0.5\"  # cost associated with the false positive \n",
        "        # and false negative error. If set to '0.5', both errors are treated as equally important\n",
        "        #  If set to 'balanced' the error of the minority classes is upweighted \n",
        "        # such that the product of the error-weight and the proportion of objects\n",
        "        # in the class is equivalent for both classes.\n",
        "\n",
        "        # The error costs can also be set to arbitrary values using a dictionary,\n",
        "        # e.g. {0: 0.1, 1: 0.9}. This means that the error in the positive class\n",
        "        # are 9 times more important than the error in the negative class.\n",
        "\n",
        "        self.exp_do_upsample = False  # whether the minority class is upsampled \n",
        "        # according to the error costs (see above). If False, the objects are weighted\n",
        "        # according to the error costs. Note that the weighting of objects is not\n",
        "        # supported by all algorithms.\n",
        "\n",
        "        self.exp_bootstrap = \"no\" # bootstrapping the training set with the options\n",
        "        # no (no bootstrappoing), up (upsampling), down (downsampling)\n",
        "        self.exp_bootstrap_replace = \"no\" # # whether to resample the minority class by replacement as well\n",
        "\n",
        "\n",
        "    def _make_name(self, name_appx=\"\"):\n",
        "        \"\"\"Creates a descriptive name according to the configuration.\n",
        "        This name is used when saving the files in the results folder.\n",
        "        It is based on some of the experiments parameters but the user\n",
        "        can also add a suffix to the name with the name_appx argument\n",
        "        \"\"\"\n",
        "        name_data = name_appx +  str(self.data_horizon) + \"_\" + str(self.exp_id)\n",
        "\n",
        "        if self.exp_year_split is None:\n",
        "            expName = \"CV\"\n",
        "        else:\n",
        "            expName = \"year\" + str(int(self.exp_year_split))\n",
        "        name = self.data_period + \"_\" + str(expName) + \"_\" + str(name_data)\n",
        "\n",
        "        if self.data_include_crisis_year:\n",
        "            name = name + \"crsIncl_\"\n",
        "\n",
        "        if self.exp_do_shapley:\n",
        "            name = name + \"SHAP_\"\n",
        "\n",
        "\n",
        "        return name"
      ],
      "metadata": {
        "id": "mB37Cgje1CB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5TBd_aTyJ93",
        "outputId": "e4cb6f82-cfbf-495f-9888-24d7e532ab18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from shap) (1.7.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from shap) (1.21.6)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap) (1.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap) (5.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap) (3.11.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyrGbjb1x4vW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This script provides utility functions that are used in the experiments\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as st\n",
        "import shap\n",
        "import os\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import mstats\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "\n",
        "def shapley_kernel_wrapper(model, trainx, testx, config):\n",
        "    \"\"\" This function is called by the prediction algorithms (ml_functions) \n",
        "    to compute the Shapley values. Note that the decision tree based models\n",
        "    such as random forest do provide faster and exact (non-approximated)\n",
        "     Shapley values with the TreeShapExplainer\"\"\"\n",
        "    if config.exp_shap_background >= trainx.shape[0]:\n",
        "        background = trainx\n",
        "    else:\n",
        "        background = shap.kmeans(trainx, config.exp_shap_background)\n",
        "\n",
        "        # random sample of background values\n",
        "        # ixx = np.random.choice(trainx.shape[0], config.exp_shap_background, replace=False)\n",
        "        # background = trainx[ixx, :]\n",
        "        # print(background.shape)\n",
        "\n",
        "        explainer = shap.KernelExplainer(model.predict_proba, background)\n",
        "        if isinstance(model, LogisticRegression):  # one background instance is enough if we use a linear model\n",
        "            background = shap.kmeans(trainx, 1)\n",
        "            backup_base = explainer.fnull\n",
        "            explainer = shap.KernelExplainer(model.predict_proba, background)\n",
        "            explainer.fnull = backup_base\n",
        "\n",
        "    fnull_save = explainer.fnull[1]\n",
        "    out = [explainer.shap_values(testx[i, :], l1_reg=0.0)[1] for i in np.arange(len(testx))]\n",
        "    return np.vstack(out)\n",
        "\n",
        "def exclude_periods(data, config):\n",
        "    \"\"\" the function sets all cue values on the excluded periods to NA and returns\n",
        "     an index of all the objects that should later be deleted.\n",
        "     This way of processing ist best because all the preprocessing functions do not need\n",
        "     consider cases where years are already missing \"\"\"\n",
        "\n",
        "    exclude_ix = np.zeros(len(data)) > 1\n",
        "\n",
        "    if config.data_exclude_extreme_period:\n",
        "        # exclude great depression | but NOT the beginnig of this crisis\n",
        "        exclude_ix = exclude_ix | (np.array(data[\"year\"] > 1933) & np.array(data[\"year\"] < 1939))\n",
        "        # exclude WW1\n",
        "        exclude_ix = exclude_ix | (np.array(data[\"year\"] > 1913) & np.array(data[\"year\"] < 1919))\n",
        "        # exclude WW2\n",
        "        exclude_ix = exclude_ix | (np.array(data[\"year\"] > 1938) & np.array(data[\"year\"] < 1946))\n",
        "\n",
        "    if not config.data_period in ['all', 'pre-ww2', 'post-ww2']:\n",
        "        raise ValueError(\"time split is either 'all', 'pre-ww2', or 'post-ww2'\")\n",
        "\n",
        "    elif config.data_period  == 'pre-ww2':\n",
        "        exclude_ix = exclude_ix | np.array(data[\"year\"] > 1939)\n",
        "\n",
        "    elif config.data_period == 'post-ww2':\n",
        "        exclude_ix = exclude_ix | np.array(data[\"year\"] < 1946)\n",
        "\n",
        "    feature_names = set(data.columns.values).difference(set(['year', 'country', 'iso', 'crisis_id',\n",
        "                                                             'crisis']))\n",
        "    # set all feature values to NA in the excluded periods\n",
        "    data.loc[exclude_ix, feature_names] = np.nan\n",
        "\n",
        "    return data, exclude_ix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_grouped_folds(y, y_group, y_group_2=None, nfolds=10, reps=1, balance=True):\n",
        "    \"\"\"Create folds such that all objects in the same y_group and in the same\n",
        "    y_group_2 (if not none) are assigned\n",
        "    to the same fold\n",
        "    :param np.array y: Binary outcome variable\n",
        "    :param np.array y_group: Grouping variable, e.g crisis indicator\n",
        "    :param np.array y: Second grouping variable (optional)\n",
        "    :param int nfolds: Number of folds\n",
        "    :param int reps: Number of replications of the n-fold cross-validation\n",
        "    :param bool balance: If true, the outcome y is balanced as much as possible,\n",
        "        i.e. that there are an equal number of\n",
        "        positive observations in each fold\n",
        "    \"\"\"\n",
        "    no = y.size\n",
        "    iterable = list()\n",
        "    for r in np.arange(reps):\n",
        "        placed = np.zeros(no, dtype=np.int64)\n",
        "        out = np.zeros(no, dtype=np.int64)*np.nan\n",
        "        pos_counter = np.zeros(nfolds, dtype=np.int64)\n",
        "        neg_counter = np.zeros(nfolds, dtype=np.int64)\n",
        "\n",
        "        # go through objects in random order\n",
        "        oo = np.random.choice(np.arange(no), no, replace=False)\n",
        "        for i in oo:\n",
        "            if placed[i] == 0:\n",
        "                if not y_group_2 is None: # no verlap in year AND crisis_id\n",
        "                    ix = np.where((y_group[i] == y_group) | (y_group_2[i] == y_group_2))[0]\n",
        "                    for i in np.arange(25):\n",
        "                        ix = np.where(np.in1d(y_group, y_group[ix]) | np.in1d(y_group_2, y_group_2[ix]))[0]\n",
        "                else: # no overlap in crisis_id\n",
        "                    ix = np.where(y_group[i] == y_group)[0]\n",
        "\n",
        "                placed[ix] = 1\n",
        "\n",
        "                if balance:\n",
        "                    if y[i] == 1:\n",
        "                        rf = np.random.choice(np.where(pos_counter == pos_counter.min())[0])\n",
        "                        pos_counter[rf] += ix.size\n",
        "                    else:\n",
        "                        rf = np.random.choice(np.where(neg_counter == neg_counter.min())[0])\n",
        "                        neg_counter[rf] += ix.size\n",
        "                else:\n",
        "                    rf = int(np.random.randint(0, nfolds, 1))\n",
        "\n",
        "                out[ix] = rf\n",
        "\n",
        "        for f in np.arange(nfolds):\n",
        "            ix_train = np.where(out != f)[0]\n",
        "            ix_test = np.where(out == f)[0]\n",
        "            # make sure that test set contains both classes\n",
        "            if (not (y[ix_test].mean() == 0)) & (not (y[ix_test].mean() == 1)):\n",
        "                iterable.append((ix_train, ix_test))\n",
        "\n",
        "    if len(iterable) < nfolds*reps:\n",
        "        print(\"Repeat folding, some test set had zero variance in criterion\")\n",
        "        return create_grouped_folds(y, y_group, y_group_2=y_group_2,\n",
        "                                  nfolds=nfolds, reps=reps, balance=balance)\n",
        "    else:\n",
        "        return iterable, out\n",
        "\n",
        "def create_forecasting_folds(y, year, min_crisis=20, temp_resolution=1):\n",
        "    \"\"\" Create folds for the forecasting experiment\n",
        "     :param np.array y: Binary outcome variable\n",
        "     :param np.array year: Time stamp for each observation\n",
        "     :param int min_crisis: Minimum number of crisis observations in the training set.\n",
        "     :param int temp_resolution: After how many years a new model should be trained.\n",
        "     The default is 1, meaning, a new model is trained for every year.\n",
        "    \"\"\"\n",
        "    iterable = list()\n",
        "    last_train_year = list()\n",
        "    uni_years = sorted(year.unique())\n",
        "    del uni_years[-1]\n",
        "    for i in np.arange(len(uni_years)):\n",
        "        n_crisis = y[year <= uni_years[i]].sum()\n",
        "        if (n_crisis >= min_crisis) & ((uni_years[i] % temp_resolution) == 0):\n",
        "            ix_train = np.where(year <= uni_years[i-1])[0]\n",
        "            ix_test = np.where(year > uni_years[i - 1])[0]\n",
        "\n",
        "            if (len(ix_train) > 0) & (len(ix_test) > 0):\n",
        "                iterable.append((ix_train, ix_test))\n",
        "                last_train_year.append(uni_years[i])\n",
        "    return iterable, last_train_year\n",
        "\n",
        "\n",
        "def hyperparam_search(model, parameters, use='grid', n_jobs=1, cv=None, scoring=None,\n",
        "                  n_iter=250, verbose=False):\n",
        "    \"\"\"Create a Grid or random search object that can be processed by Scikit-learn\"\"\"\n",
        "    if isinstance(cv, int):\n",
        "        raise ValueError(\"The argument cv should not be a number because the GridSearch algorithms\"\n",
        "                         \" in sklearn do always create the same folds even with differnt random seeds.\"\n",
        "                         \" Rather you should pass folds that were created by our own function create_grouped_folds\")\n",
        "\n",
        "\n",
        "    if np.cumprod([len(parameters[x]) for x in parameters.keys()]).max() <= n_iter: # do use gridsearch if less than n_iter\n",
        "        use = \"grid\" # combinations are tested\n",
        "    if use == 'grid':\n",
        "        model_out = GridSearchCV(model, parameters, n_jobs=n_jobs, cv=cv,\n",
        "                                 scoring=scoring, verbose=verbose, iid = True)\n",
        "    if use == 'random':\n",
        "        model_out = RandomizedSearchCV(model, parameters, n_jobs=n_jobs, \n",
        "                                       cv=cv, n_iter=n_iter, scoring=scoring,\n",
        "\n",
        "                                       verbose=verbose)\n",
        "    return model_out\n",
        "\n",
        "\n",
        "def write_file(data, file_name, path = '../results/', round=3, format=\".txt\",\n",
        "              short_name=6, append=False, shorten = True):\n",
        "      \n",
        "    \"\"\" Writes a table as a text file to the hard drive \"\"\"\n",
        "    out = data.round(round)\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "    if isinstance(data, pd.core.frame.DataFrame):\n",
        "        if shorten:\n",
        "            out.columns = [x.replace(\"_\" , \"\")[0:short_name] for x in out.columns.values]\n",
        "            out.index = [str(x).replace('_', ' ')[0:short_name] for x in out.index.values]\n",
        "        if append:\n",
        "            out.to_csv(path + file_name + format , sep='\\t', mode = 'a', header=True)\n",
        "        else:\n",
        "            out.to_csv(path + file_name + format, sep='\\t', header=True)\n",
        "\n",
        "\n",
        "def weights_from_costs(costs, Y):\n",
        "    \"\"\"  Weights observations according to the costs of the errors (as speceificed by the user) of the two classes.\n",
        "    For example if the cost vector is [0.5, 0.5] and class A is twice as prevalent as class B,\n",
        "    objects in class B will get twice the weight as objects in class A. \"\"\"\n",
        "    p1 = Y.mean()\n",
        "    weights = {}\n",
        "    weights[1] = costs[1] / (p1 * costs[1] + (1-p1) * costs[0])\n",
        "    weights[0] = costs[0] / (p1 * costs[1] + (1 - p1) * costs[0])\n",
        "    return weights\n",
        "\n",
        "\n",
        "def downsample(X, Y, costs={0:0.5, 1: 0.5}, group=None):\n",
        "    \"\"\" downsample the majority class according to the costs of the errors. \"\"\"\n",
        "    if group is None:\n",
        "        group = np.arange(len(Y))\n",
        "    weights = weights_from_costs(costs, Y)\n",
        "\n",
        "    ix_pos = np.where(Y == 1)[0]\n",
        "    n_pos = ix_pos.size\n",
        "    ix_neg = np.where(Y == 0)[0]\n",
        "    n_neg = ix_neg.size\n",
        "    norm_w = min(weights.values())\n",
        "    weights[0] = weights[0] / norm_w\n",
        "    weights[1] = weights[1] / norm_w\n",
        "\n",
        "    if weights[0] > weights[1]:\n",
        "      ix_pos = np.random.choice(ix_pos, size=int(round(n_pos/weights[0])), replace=True)\n",
        "    else:\n",
        "      ix_neg = np.random.choice(ix_neg, size=int(round(n_neg/weights[1])), replace=True)\n",
        "    ixses = np.concatenate((ix_pos, ix_neg))\n",
        "    ixses = np.random.choice(ixses, size=ixses.size, replace=False)\n",
        "    return X[ixses, :], Y[ixses], group[ixses]\n",
        "\n",
        "def upsample(X, Y, group, costs):\n",
        "    \"\"\" upsamples the minority class \"\"\"\n",
        "    weights = weights_from_costs(costs, Y)\n",
        "\n",
        "    ix_pos = np.where(Y == 1)[0]\n",
        "    n_pos = ix_pos.size\n",
        "    ix_neg = np.where(Y == 0)[0]\n",
        "    n_neg = ix_neg.size\n",
        "    norm_w = min(weights.values())\n",
        "    weights[0] = weights[0] / norm_w\n",
        "    weights[1] = weights[1] / norm_w\n",
        "\n",
        "    if weights[1] > weights[0]:\n",
        "      ix_pos = np.random.choice(ix_pos, size=int(round(weights[1] * n_pos)), replace=True)\n",
        "    else:\n",
        "      ix_neg = np.random.choice(ix_neg, size=int(round(weights[0] * n_neg)), replace=True)\n",
        "    ixses = np.concatenate((ix_pos, ix_neg))\n",
        "    ixses = np.random.choice(ixses, size=ixses.size, replace=False)\n",
        "\n",
        "    return X[ixses, :], Y[ixses], group[ixses]\n",
        "\n",
        "\n",
        "# UTILITIES FOR TRANSFORMING VARIABLES #\n",
        "\n",
        "def make_ratio(data_input, variables, denominator=\"gdp\"):\n",
        "    \"\"\" Computes the ratio of two variables. By detault the denominator is GDP. \"\"\"\n",
        "\n",
        "    names_out = []\n",
        "    if isinstance(variables, str):\n",
        "        variables = [variables]\n",
        "    data = data_input.copy()\n",
        "    for var in variables:\n",
        "        varname = var + '_' + denominator\n",
        "        data[varname] = data[var] / data[denominator]\n",
        "        names_out.append(varname)\n",
        "    return data, names_out\n",
        "\n",
        "def make_shift(data_input, variables, type, horizon=5):\n",
        "    \"\"\" Computes the change of a variable with respect to a certain horizon.\n",
        "     :param pd.dDtaFrame data_input: Dataset. The tranformed variable will be appended to that data\n",
        "     :param list of str variables : Name of the variables in data_input that will be transformed\n",
        "     :param str type: Type of transformation. Either \"absolute\" (change) or \"percentage\" (change).\n",
        "    \"\"\"\n",
        "    \n",
        "    names_out = []\n",
        "    data = data_input.copy()\n",
        "    data_group = data.groupby('iso')\n",
        "    if isinstance(variables, str):\n",
        "        variables = [variables ]\n",
        "    for var in variables:\n",
        "        if type == \"absolute\":\n",
        "            varname = var + '_rdiff' + str(horizon)\n",
        "            data[varname] = data_group[var].diff(horizon)\n",
        "        elif type == \"percentage\":\n",
        "            varname = var + '_pdiff' + str(horizon)\n",
        "            # attention objects must be ordered by year and country as they are in the original data\n",
        "            data[varname] = data_group[var].apply(lambda x: lag_pct_change(x, h=horizon))\n",
        "            #data[varname] = data_group[var].pct_change(horizon)\n",
        "\n",
        "        names_out.append(varname)\n",
        "    return data, names_out\n",
        "\n",
        "def lag_pct_change(x, h):\n",
        "    \"\"\" Computes percentage changes \"\"\"\n",
        "    lag = np.array(pd.Series(x).shift(h))\n",
        "    return (x - lag) / lag\n",
        "\n",
        "\n",
        "\n",
        "def make_level_change(data_input, variables, type, horizon=10):\n",
        "    \"\"\" Computes the hamilton filter or difference from moving average\n",
        "     :param pd.dDtaFrame data_input: Dataset. The tranformed variable will be appended to that data\n",
        "     :param list of str variables: Name of the variables in data_input that will be transformed\n",
        "     :param str type: Type of transformation. Either \"ham\" (hamilton filter) or \"mad\" (movgin average difference).\n",
        "    \"\"\"\n",
        "    names_out = []\n",
        "    data = data_input.copy()\n",
        "    data_grouped = data.groupby('iso')\n",
        "    if isinstance(variables, str):\n",
        "        variables = [variables]\n",
        "    for var in variables:\n",
        "        if type == \"mad\":\n",
        "            varname = var + '_mad'\n",
        "            data[varname] = np.nan\n",
        "            data_mad = pd.DataFrame(data_grouped.apply(mov_ave_diff, var, horizon), \n",
        "                                    columns=[varname])\n",
        "            for iso in data_mad.index.values:\n",
        "                data.loc[data.iso == iso, varname] = data_mad.loc[iso, varname]\n",
        "\n",
        "        if type == \"ham\":\n",
        "            varname = var + '_ham'\n",
        "            data[varname] = np.nan\n",
        "            data_ham = pd.DataFrame(data_grouped.apply(hamilton_filter, var, 2, 4),\n",
        "                                    columns=[varname])\n",
        "            for iso in data_ham.index.values:\n",
        "                data.loc[data.iso == iso, varname] = data_ham.loc[iso, varname]\n",
        "        names_out.append(varname)\n",
        "    return data, names_out\n",
        "\n",
        "\n",
        "def make_relative_change(data_input, variables, index='gdp', horizon=5):\n",
        "    \"\"\" Computes the change of a variable relative the the change of of another variable\n",
        "     :param pd.dDtaFrame data_input: Dataset. The tranformed variable will be appended to that data\n",
        "     :param list of str variables: Name of the variables in data_input that will be transformed\n",
        "     :param str index: Name of the variables to which the change is relative to (default is GDP)\n",
        "    \"\"\"\n",
        "    names_out = []\n",
        "    data = data_input.copy()\n",
        "    data_grouped = data.groupby('iso')\n",
        "    if isinstance(variables, str):\n",
        "        variables = [variables]\n",
        "    for var in variables:\n",
        "        varname = var + '_idiff' + str(horizon)\n",
        "        data[varname] = np.nan\n",
        "        data_idiff = pd.DataFrame(data_grouped.apply(index_ratio_change, var,\n",
        "                                                     index, horizon), columns=[varname])\n",
        "        for iso in data_idiff.index.values:\n",
        "            data.loc[data.iso == iso, varname] = data_idiff.loc[iso, varname]\n",
        "        names_out.append(varname)\n",
        "    return data, names_out\n",
        "\n",
        "\n",
        "def mov_ave_diff(group, col, L=10):\n",
        "    \"\"\" Computes the gap between a moving average (of length L) and the\n",
        "    observations on a grouped data set \"\"\"\n",
        "    values = group[col].values\n",
        "    N = len(values)\n",
        "    out = np.zeros(N) * np.nan\n",
        "    if N >= L:\n",
        "        for i in range(N - L + 1):\n",
        "            out[i + L - 1] = values[i + L - 1] - np.mean(values[i-1:i + L-1])\n",
        "    return out\n",
        "\n",
        "def index_ratio_change(group, ind1, ind2, l=5):\n",
        "    \"\"\"relative change of ind1 to ind2 over period l for group values.\"\"\"\n",
        "\n",
        "    val1 = group[ind1].values\n",
        "    val2 = group[ind2].values\n",
        "    N = len(val1)\n",
        "    out = np.zeros(N) * np.nan\n",
        "\n",
        "    if N >= l:\n",
        "        for i in range(N - l):\n",
        "            out[i + l] = (val1[i + l]  / val1[i]) / (val2[i + l] / val2[i]) - 1\n",
        "    return out\n",
        "\n",
        "\n",
        "def hamilton_filter(group, col, h=2, p=4, output=\"cycle\"):  \n",
        "    \"\"\" computes Hamilton filter\n",
        "    : param int h: look-head period\n",
        "    : param int p: number of lagged variables\n",
        "    \"\"\"\n",
        "\n",
        "    x = group[col].values\n",
        "    # note: Hamilton used 100 times x's logrithm in his employment data,\n",
        "    # however, this is commented out because our data has negative values\n",
        "    # x = 100*np.log(x)\n",
        "    # Get the trend/predicted series\n",
        "    trend = hamilton_filter_glm(x, h, p)\n",
        "    if trend is not None:  # if dataframe passed is not full of nans\n",
        "        # Get the cycle which is simple the original series substracted by the trend\n",
        "        cycle = x - trend\n",
        "        # Get the random walk series which is simply the difference between\n",
        "        # the original series and the h look back\n",
        "        df_x = pd.DataFrame(x)\n",
        "        df_x_h = df_x.shift(h)\n",
        "        random = df_x - df_x_h\n",
        "    else:\n",
        "        trend = x\n",
        "        cycle = x\n",
        "        random = x\n",
        "    # Return required series in result, if all is selected then all results\n",
        "    # are returned in a data frame\n",
        "    if (output == \"x\"):\n",
        "        return x\n",
        "    elif (output == \"trend\"):\n",
        "        return trend\n",
        "    elif (output == \"cycle\"):\n",
        "        return np.asarray(cycle)\n",
        "    elif (output == \"random\"):\n",
        "        return random\n",
        "    elif (output == \"all\"):\n",
        "        df = pd.DataFrame()\n",
        "        df['x'] = x\n",
        "        df['trend'] = trend\n",
        "        df['cycle'] = cycle\n",
        "        df['random'] = random\n",
        "        df.plot()\n",
        "        # pyplot.show()\n",
        "        return df\n",
        "    else:\n",
        "        print ('\\nInvalid output type')\n",
        "\n",
        "\n",
        "\n",
        "def hamilton_filter_glm(x, h=2, p=4):\n",
        "    \"\"\" Runs the linear model for the specification of the hamilton filter \"\"\"\n",
        "    # Create dataframe for time series to be smoothed, the independent variable y\n",
        "    df = pd.DataFrame(x)\n",
        "    df.columns = ['yt8']\n",
        "    # Create matrix of dependent variables X which are the shifts of 8 period back\n",
        "    # for 4 consecutive lags on current time t\n",
        "    for lag in range(h, (h + p)):\n",
        "        df['xt_' + str(lag - h + 1)] = df.yt8.shift(lag)\n",
        "    # Getting the dependent varaibles X's index names\n",
        "    X_columns = []\n",
        "    for i in range(1, p + 1):\n",
        "        new_s = 'xt_' + str(i)\n",
        "        X_columns.append(new_s)\n",
        "    # y and X variables for regression\n",
        "    y = df['yt8']\n",
        "    X = df[X_columns]\n",
        "\n",
        "    xt_0 = pd.DataFrame(np.ones((df.shape[0], 1)))\n",
        "    xt_0.columns = ['xt_0']\n",
        "    X = xt_0.join(X)\n",
        "    # Build the OLS regression model and drop the NaN\n",
        "    try:\n",
        "        if (sum(np.isnan(y)) != y.size):\n",
        "            model = sm.OLS(y, X, missing='drop').fit()\n",
        "            # Optional: print out the statistics\n",
        "            model.summary()\n",
        "            predictions = model.predict(X)\n",
        "            return predictions\n",
        "        else:\n",
        "            return y\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "def all_same(items):\n",
        "    return all(x==items[0] for x in items)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoidinv(x):\n",
        "  return -np.log(1.0/x -1)\n",
        "\n",
        "def normalize(data):\n",
        "  return data.apply(normalizeV)\n",
        "\n",
        "def normalizeV(x):\n",
        "  x = x.astype(dtype=\"float32\")\n",
        "  return (x- np.nanmin(x))/(np.nanmax(x) - np.nanmin(x))\n",
        "\n",
        "def performance_results(Y_in, Y_pred_in, threshold = 0.5):\n",
        "    \"\"\" Computes performance metrics\n",
        "    : param np.array Y_in: true values (0 or 1) of the response variable\n",
        "    : param np.array Y_pred_in: predicted values of the response variable (between 0 an 1)\n",
        "    : param float threshold: if Y_pred_in >= threshold, the predcited class is positive, otherwise negative\n",
        "    \"\"\"\n",
        "    Y_pred_in = np.array(Y_pred_in, dtype=float)\n",
        "    # types of Y and Y_pred are pd.Seres\n",
        "    ix_miss = np.isnan(Y_pred_in)\n",
        "\n",
        "    Y = Y_in[~ix_miss].copy()\n",
        "    Y_pred = Y_pred_in[~ix_miss].copy()\n",
        "\n",
        "    n = Y.size\n",
        "    Y = Y * 1 # typecast boolean variables\n",
        "    Y_pred = Y_pred * 1  # typecast boolean variables\n",
        "\n",
        "    Y_bool = np.array(Y,dtype = \"bool\")\n",
        "    Y_pred_bool = Y_pred >= threshold\n",
        "    # True positive (tp), ture negative (tn), false positive (fp), false negative (fn)\n",
        "    tp = np.logical_and(Y_bool, Y_pred_bool).sum()\n",
        "    tn = np.logical_and(~Y_bool, ~Y_pred_bool).sum()\n",
        "    fp = np.logical_and(~Y_bool, Y_pred_bool).sum()\n",
        "    fn = np.logical_and(Y_bool, ~Y_pred_bool).sum()\n",
        "\n",
        "    out = dict()\n",
        "    if any(pd.isna(Y_pred)):\n",
        "        return dict([\n",
        "            (\"accuracy\", float(\"nan\")),\n",
        "            (\"balanced\", float(\"nan\")),\n",
        "            (\"tp_rate\", float(\"nan\")),\n",
        "            (\"fp_rate\", float(\"nan\")),\n",
        "            (\"auc\", float(\"nan\")),\n",
        "            (\"tp\", float(\"nan\")),\n",
        "            (\"tn\", float(\"nan\")),\n",
        "            (\"fp\", float(\"nan\")),\n",
        "            (\"fn\", float(\"nan\")),\n",
        "        ])\n",
        "    else:\n",
        "        out['tp'] = tp\n",
        "        out['tn'] = tn\n",
        "        out['fp'] = fp\n",
        "        out['fn'] = fn\n",
        "        out['accuracy'] = float(tp + tn) / float(n)\n",
        "        if ((tp + fn == 0)):\n",
        "            out['tp_rate'] = float(\"nan\")\n",
        "        else:\n",
        "            out['tp_rate'] = float(tp) / float(tp + fn)\n",
        "\n",
        "        if (tn + fp == 0):\n",
        "            out['fp_rate'] = float(\"nan\")\n",
        "        else:\n",
        "            out['fp_rate'] = 1 - float(tn) / float(tn + fp)\n",
        "\n",
        "        out['balanced'] = (out[\"tp_rate\"] + (1 - out[\"fp_rate\"])) / 2.0\n",
        "\n",
        "        if ((tp + fn > 0) & (tn + fp > 0)):\n",
        "            out['auc'] = roc_auc_score(Y_bool, Y_pred)\n",
        "        else:\n",
        "            out['auc'] = float('nan')\n",
        "        return out\n",
        "\n",
        "\n",
        "def remove_file(file_path):\n",
        "    \"\"\" removes file from hard drive \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script loads the Jorda-Schularick-Taylor Macrohistry database and transforms the variables.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def create_data(config):\n",
        "    \"\"\" Create the data set from the raw data from \"http://www.macrohistory.net/data/\"\n",
        "    according to the specifications in the Config object\"\"\"\n",
        "    \n",
        "    # the data can be downlaoded directly:\n",
        "    # df_jst = pd.read_excel('http://www.macrohistory.net/JST/JSTdatasetR3.xlsx', sheet_name=\"Data\") \n",
        "    df_jst = pd.read_excel('data/JSTdatasetR3.xlsx', sheet_name=\"Data\") \n",
        "    df = df_jst.copy()\n",
        "    # rename variables\n",
        "    df.rename(columns={\n",
        "        \"crisisJST\": \"crisis\",\n",
        "        'stir': 'srate',\n",
        "        'ltrate': 'lrate',\n",
        "        'iy': 'inv_gdp',\n",
        "        'debtgdp': 'pdebt_gdp',\n",
        "        'money': 'bmon',\n",
        "        'narrowm': 'nmon',\n",
        "        'tloans': 'tloan',\n",
        "        'tbus': 'bloan',\n",
        "        'thh': 'hloan',\n",
        "        'tmort': 'mort',\n",
        "        'stocks': 'stock',\n",
        "        'hpnom': 'hp',\n",
        "        'rconpc': 'cons'\n",
        "    }, inplace=True)\n",
        "\n",
        "    horizon = config.data_horizon\n",
        "    predictors = config.data_predictors\n",
        "    # we do not compute growth rates for the interest rates and the slope for the yield curve.\n",
        "    no_change = [\"drate\",  \"global_drate\", \"lrate\", \"srate\"]\n",
        "\n",
        "    # For the other predictors we compute growth rate (percentage change or ratio change)\n",
        "    # and add the horizon (e.g. 2 year change) to the variable name\n",
        "    predictors = [p + str(horizon) for p in predictors if p not in no_change] +\\\n",
        "        list(set(predictors).intersection(set(no_change)))\n",
        "\n",
        "    df, exclude_ix = exclude_periods(df, config)  # exclude periods that are not normal economic conditions (e.g. WW2)\n",
        "\n",
        "    df.loc[:, 'drate'] = df['lrate'] - df['srate']  # rate differential\n",
        "\n",
        "    df.loc[:, 'pdebt'] = df['pdebt_gdp'] * df['gdp'] # compute public debt from public debt/gdp ratio\n",
        "    df.loc[:, 'inv'] = df['inv_gdp'] * df['gdp']  # compute investment from investment/gdp ratio\n",
        "\n",
        "    # Calculaute debt to service ratios\n",
        "    df.loc[:, 'tdbtserv'] = df['tloan'] * df['lrate'] / 100.0\n",
        "    \n",
        "    pre_gdp_ratios = ['bmon', 'nmon', 'tloan', 'bloan',\n",
        "                      'hloan', 'mort', 'ca', 'cpi', 'tdbtserv',\n",
        "                      'inv', 'pdebt'] # vector of variables that will be transformed by GDP ratio\n",
        "    df, gdp_ratios = make_ratio(df, pre_gdp_ratios, denominator='gdp')\n",
        "\n",
        "    # here we compute the transformations and att the variables to the dataset df \n",
        "\n",
        "    # ratio change by GDP (rdiff)\n",
        "    df, _ = make_shift(df, [\"lrate\", \"srate\", \"drate\"] + gdp_ratios,\n",
        "                       type=\"absolute\", horizon=horizon)\n",
        "    # percentage change (pdiff)\n",
        "    df, _ = make_shift(df, ['stock', 'cpi', 'hp', 'cons', 'gdp'] + pre_gdp_ratios,\n",
        "                       type=\"percentage\",\n",
        "                       horizon=horizon)  # do not use absolute change\n",
        "    # hamilton filter (ham)\n",
        "    df, _ = make_level_change(df, [\"cons\"] + gdp_ratios, type=\"ham\")\n",
        "\n",
        "\n",
        "    # --- Computing global variables --- #\n",
        "\n",
        "    # global credit growth (global_loan)\n",
        "    for year in df[\"year\"].unique():\n",
        "        ix = df[\"year\"] == year\n",
        "        for country in df[\"iso\"].unique():\n",
        "            # computing the average across all countries but the selected one\n",
        "            perc_pos = df.loc[ix.values & (df.iso != country).values,\n",
        "                              \"tloan_gdp_rdiff\" + str(horizon)].mean()\n",
        "\n",
        "            if not np.isnan(perc_pos):\n",
        "                df.loc[ix.values & (df.iso == country).values,\n",
        "                       \"global_loan\" + str(horizon)] = perc_pos\n",
        "\n",
        "    # global slope of the yield curve\n",
        "    for year in df[\"year\"].unique():\n",
        "        ix = df[\"year\"] == year\n",
        "        for country in df[\"iso\"].unique():\n",
        "            # computing the average across all countries but the selected one\n",
        "            perc_pos = df.loc[ix.values & (df.iso != country).values, \"drate\"].mean()\n",
        "\n",
        "            if not np.isnan(perc_pos):\n",
        "                df.loc[ix.values & (df.iso == country).values, \"global_drate\"] = perc_pos\n",
        "\n",
        "    # check whether we have created all features that will be used in the experiment\n",
        "    if len(set(predictors).difference(set(df.columns.values))) > 0:\n",
        "        raise ValueError('Features ' + ', '.join(set(predictors).difference(set(df.columns.values))) + \"\\n\" +\n",
        "                         \"could not be found in the data!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # --- creating the 'landing zone' on the crisis outcome --- #\n",
        "    years = df.year.values\n",
        "    isos = df['iso'].values\n",
        "\n",
        "    crisis_in = df_jst.crisisJST.values == 1\n",
        "    crisis = crisis_in * 0\n",
        "    for i, (yr, cr) in enumerate(zip(years, crisis_in)):\n",
        "        if cr:\n",
        "            for l in np.arange(1, 1 + config.data_years_pre_crisis): # flagging years before crisis as positive \n",
        "                if yr > (np.min(years) + l - 1):\n",
        "                    crisis[i - l] = 1\n",
        "            if config.data_include_crisis_year: \n",
        "                crisis[i] = 1  # crisis year\n",
        "\n",
        "    # --- treatment of actual crisis and post crisis observations --- #\n",
        "    i_keep = np.ones(len(df), dtype=int)\n",
        "    for i, (yr, cr, iso) in enumerate(zip(years, crisis_in, df.iso)):\n",
        "        if cr:\n",
        "            if not config.data_include_crisis_year: \n",
        "                i_keep[i] = 0\n",
        "\n",
        "            for j in range(1, 1 + config.data_post_crisis):\n",
        "                k = i + j\n",
        "                if (iso == df.iso[k]) & (k < len(df)):\n",
        "                    i_keep[k] = 0\n",
        "\n",
        "    # --- Give all observations of the same crisis the same ID --- #\n",
        "    # This ID is used for cross-validation to make sure that the same crisis\n",
        "    # is not in the training and test set\n",
        "    # This function generalizes to any length of crises\n",
        "\n",
        "    crisis_id = np.zeros(len(df))\n",
        "    count = int(1)\n",
        "    for i in np.arange(2, len(df)):\n",
        "        if crisis[i] == 1:\n",
        "            if not ((crisis[i - 1] == 1) & (isos[i] == isos[i - 1])):\n",
        "                count += 1\n",
        "            crisis_id[i] = count\n",
        "    # All other observations get unique identifier\n",
        "    crisis_id[crisis_id == 0] = np.random.choice(sum(crisis_id == 0),\n",
        "                                                 size=sum(crisis_id == 0),\n",
        "                                                  replace=False) + 2 + int(max(crisis_id))\n",
        "\n",
        "    # create the data set\n",
        "    features = df.loc[:, predictors]\n",
        "    data = features\n",
        "    data['crisis'] = crisis.astype(int)\n",
        "    data['crisis_id'] = crisis_id.astype(int)\n",
        "    data['year'] = years.astype(int)\n",
        "    data['iso'] = isos # name of countries\n",
        "\n",
        "    exclude_ix = exclude_ix | (i_keep == 0)\n",
        "    data = data.loc[~exclude_ix, :]\n",
        "\n",
        "    data = data.dropna()  # remove missing values\n",
        "    data = data.reset_index(drop=True)  # update index\n",
        "    return data"
      ],
      "metadata": {
        "id": "-Vl4EuKc1JJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script contains wrapper functions for the different machine learning methods.\n",
        "\"\"\"\n",
        "import os\n",
        "import shap\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "from sklearn import svm as sk_svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.utils import resample\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "\n",
        "# Hyperparameter space for the support vector machines\n",
        "svm_cspace = 2. ** np.linspace(-5., 10., 10)\n",
        "svm_gammaspace = 2. ** np.linspace(-10., 3., 10)\n",
        "\n",
        "\n",
        "class PredictionModel:\n",
        "\n",
        "    \"\"\" This class is used to train all models, compute the Shapley values, and \n",
        "        summarise the output in a dictionary\n",
        "    \"\"\"\n",
        "    def __init__(self, model, name, data, config, **kwargs):\n",
        "        \"\"\"\n",
        "         :param object model: Prediction model object in the standard sklearn format.\n",
        "         :param str name: name given to the model.\n",
        "         :param dict data: contains the training and test data\n",
        "         :param Config config: config object. \n",
        "        \"\"\"\n",
        "        self.trainx = data[\"trainx\"]\n",
        "        self.trainy = data[\"trainy\"]\n",
        "        self.testx = data[\"testx\"]\n",
        "        self.config = config\n",
        "        self.model = model\n",
        "        self.name = name\n",
        "        start_time = time.time()\n",
        "        self._train() # train model \n",
        "        stop_time = time.time()\n",
        "\n",
        "        self.best_hyper = None\n",
        "        if hasattr(self.model, \"best_params_\"):\n",
        "            self.best_hyper = model.best_params_\n",
        "        if hasattr(self.model, \"best_estimator_\"):\n",
        "            self.model = self.model.best_estimator_\n",
        "        \n",
        "        self.shapV, self.shapV_inter = self._compute_shap() # compute Shapley values\n",
        "\n",
        "        self.output = {\n",
        "            \"name\": name,\n",
        "            \"pred\": model.predict_proba(self.testx)[:, 1],\n",
        "            \"fit\": model.predict_proba(self.trainx)[:, 1],\n",
        "            \"model\": self.model,\n",
        "            \"hyper_params\": self.best_hyper,\n",
        "            \"shapley\": self.shapV,\n",
        "            \"shapley_inter\": self.shapV_inter,\n",
        "            \"time\": stop_time - start_time\n",
        "        }\n",
        "\n",
        "    def _train(self, **kwargs): # train the prediction model and obtain preditions\n",
        "        self.model.fit(self.trainx, self.trainy, **kwargs)\n",
        "    \n",
        "    def _compute_shap(self): # compute Shapley values\n",
        "        shapV_inter = None # Shapley values of the interaction of variables\n",
        "        shapV = None # Shapley values of the individual variables\n",
        "\n",
        "        if self.config.exp_do_shapley:\n",
        "        \n",
        "            if self.name in [\"extree\", \"forest\"]: # TreeExplainer\n",
        "                explainerTree = shap.TreeExplainer(self.model)\n",
        "                shapV = explainerTree.shap_values(self.testx)[1]\n",
        "            \n",
        "                if self.config.exp_shapley_interaction: # compute Shapley interaction\n",
        "                    shapV_inter = explainerTree.shap_interaction_values(self.testx)[1]\n",
        "                \n",
        "            else: # KernelExplainer\n",
        "                shapV = shapley_kernel_wrapper(self.model, self.trainx,\n",
        "                                               self.testx, self.config)\n",
        "   \n",
        "        return (shapV, shapV_inter)\n",
        "\n",
        "def gaussianprocess(data, config, name, **kwargs):\n",
        "    \n",
        "    model = GaussianProcessClassifier()\n",
        "    model_instance = PredictionModel(model, name, data, config, **kwargs)\n",
        "    return model_instance.output\n",
        "\n",
        "\n",
        "def logreg(data, config, sample_weight, name, **kwargs):\n",
        "    # Logistic regression\n",
        "    \n",
        "    model = LogisticRegression(penalty=\"none\", solver = \"lbfgs\")\n",
        "    model_instance = PredictionModel(model, name, data, config,\n",
        "                                     sample_weight = sample_weight)\n",
        "    return model_instance.output\n",
        "\n",
        "\n",
        "\n",
        "def extree(data, config, sample_weight, cv_hyper, do_cv, name, **kwargs):\n",
        "    # Extremely randomised trees.\n",
        "    # We use the default parameters (do_cv = False) in the paper, as hyperparameter tuning does not improve the performance\n",
        "    \n",
        "    if do_cv:\n",
        "        hyperparameters = {'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "                           'max_depth': [2, 3, 4, 5, 7, 10, 12, 15, 20]\n",
        "                           }\n",
        "        model = hyperparam_search(ExtraTreesClassifier(n_estimators=1000,  n_jobs=1),\n",
        "                                    hyperparameters,\n",
        "                                    use=config.exp_search,\n",
        "                                    n_jobs=config.exp_n_kernels, cv=cv_hyper,\n",
        "                                    scoring=config.exp_optimization_metric,\n",
        "                                    n_iter=config.exp_n_iter_rsearch,\n",
        "                                    verbose=config.exp_verbose)\n",
        "    else:\n",
        "        \n",
        "        model = ExtraTreesClassifier(n_estimators=1000, n_jobs=config.exp_n_kernels)\n",
        "\n",
        "    model_instance = PredictionModel(model, name, data, config,\n",
        "                                     sample_weight = sample_weight)\n",
        "    return model_instance.output\n",
        "\n",
        "def forest(data, config, sample_weight, cv_hyper, do_cv, name, **kwargs):\n",
        "    # Random forest.\n",
        "    # We use the default parameters (do_cv = False) in the paper, as hyperparameter tuning does not imporve the performance\n",
        "\n",
        "    if do_cv:\n",
        "       \n",
        "        hyperparameters = {'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "                           'max_depth': [2, 3, 4, 5, 7, 10, 12, 15, 20]\n",
        "                           }\n",
        "        model = hyperparam_search(RandomForestClassifier(n_estimators=1000,  n_jobs=1),\n",
        "                                    hyperparameters,\n",
        "                                    use=config.exp_search,\n",
        "                                    n_jobs=config.exp_n_kernels, \n",
        "                                    cv=cv_hyper,\n",
        "                                    scoring=config.exp_optimization_metric,\n",
        "                                    n_iter=config.exp_n_iter_rsearch,\n",
        "                                    verbose=config.exp_verbose)\n",
        "\n",
        "    else:\n",
        "        \n",
        "        model = RandomForestClassifier(n_estimators=1000, n_jobs=config.exp_n_kernels)\n",
        "\n",
        "    model_instance = PredictionModel(model, name, data, config, sample_weight = sample_weight)\n",
        "    return model_instance.output\n",
        "\n",
        "def nnet_single(data, cv_hyper, config, name, **kwargs):\n",
        "    # Single neural network\n",
        "    \n",
        "    n_features = data[\"trainx\"].shape[1]\n",
        "    hyperparameters = {'alpha': 10.0 ** np.linspace(-3.0, 3.0, 10),\n",
        "                       'hidden_layer_sizes': list(\n",
        "                               set([round(n_features / 3.0), round(n_features / 2.0), n_features,\n",
        "                                    (n_features, n_features),\n",
        "                                    (n_features, round(n_features / 2.0)),\n",
        "                                    (n_features*2, n_features), \n",
        "                                    (n_features*2, n_features*2)\n",
        "                                    ])),\n",
        "                        'activation': ['tanh', 'relu']}\n",
        "    \n",
        "    # Exclude single neuron or zero neuron network\n",
        "    hyperparameters[\"hidden_layer_sizes\"] = list(set(hyperparameters[\"hidden_layer_sizes\"]).difference(set([0, (1, 0)])))\n",
        "    \n",
        "    model = hyperparam_search(MLPClassifier(solver='lbfgs'),\n",
        "                               hyperparameters,\n",
        "                               use=config.exp_search,\n",
        "                               n_jobs=config.exp_n_kernels, cv=cv_hyper,\n",
        "                               scoring=config.exp_optimization_metric,\n",
        "                               n_iter=config.exp_n_iter_rsearch,\n",
        "                               verbose=config.exp_verbose)\n",
        "    model_instance = PredictionModel(model, name, data, config)\n",
        "    return model_instance.output\n",
        "\n",
        "\n",
        "\n",
        "def nnet_multi(data, config, group, name,  **kwargs):\n",
        "    # Neural network ensemble\n",
        "    ''' Fitting this ensemble is very slow and only recommended on a high performance cluster. The ensemble #\n",
        "    searchers for hyperparameters for each of the 25 base model in the ensemble to increase the variance\n",
        "     across models '''\n",
        "    \n",
        "    resample=\"bootstrap\" # resample is one of the following [\"bootstrap\", \"copy\", \"upsample\"], \n",
        "    start = time.time()\n",
        "    n_features = data[\"trainx\"].shape[1]\n",
        "    hyperparameters = {'alpha': 10.0 ** np.linspace(-3.0, 3.0, 10),\n",
        "                       'hidden_layer_sizes': list(\n",
        "                               set([round(n_features / 3.0), round(n_features / 2.0), n_features,\n",
        "                                    (n_features, n_features),\n",
        "                                    (n_features, round(n_features / 2.0)),\n",
        "                                    (n_features*2, n_features), \n",
        "                                    (n_features*2, n_features*2)\n",
        "                                    ])),\n",
        "                        'activation': ['tanh', 'relu']}\n",
        "    \n",
        "    # Exclude single neuron or zero neuron network\n",
        "    hyperparameters[\"hidden_layer_sizes\"] = list(set(hyperparameters[\"hidden_layer_sizes\"]).difference(set([0, (1, 0)])))\n",
        "    \n",
        "    model = NnetMultiObj(resample=resample, config=config,\n",
        "                     hyperparameters=hyperparameters, group=group)\n",
        "    model_instance = PredictionModel(model, name, data, config)\n",
        "    return model_instance.output\n",
        "    \n",
        "class NnetMultiObj(BaseEstimator, ClassifierMixin):\n",
        "    # Train neural networks in the neural network ensemble  \n",
        "    \n",
        "    start = time.time()\n",
        "\n",
        "    def __init__(self, resample, config, hyperparameters, group):\n",
        "        self.models = list()\n",
        "        self.n_models = 25\n",
        "        self.resample = resample\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.config = config\n",
        "        self.group = group\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        for _ in np.arange(self.n_models):\n",
        "\n",
        "            if self.resample == \"bootstrap\":\n",
        "                x_rs, y_rs, group_rs = resample(X, y, self.group, replace=True)\n",
        "            elif self.resample == \"upsample\":\n",
        "                x_rs, y_rs, group_rs = upsample(X, y,\n",
        "                                                group=self.group,\n",
        "                                                costs={0: y.mean(), 1: 1 - y.mean()})\n",
        "            else: x_rs, y_rs, group_rs = X, y, self.group\n",
        "\n",
        "            cv_hyper, cv_fold_vector = create_grouped_folds(y_rs, group_rs, nfolds=5, reps=1)\n",
        "\n",
        "            m = hyperparam_search(MLPClassifier(solver='lbfgs'),\n",
        "                                  self.hyperparameters,\n",
        "                                  use=self.config.exp_search,\n",
        "                                  n_jobs=self.config.exp_n_kernels, cv=cv_hyper,\n",
        "                                  scoring=self.config.exp_optimization_metric,\n",
        "                                  n_iter=self.config.exp_n_iter_rsearch,\n",
        "                                  verbose=self.config.exp_verbose)\n",
        "            m.fit(x_rs, y_rs)\n",
        "            self.models.append(m)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X, y=None):\n",
        "        predm = np.zeros((X.shape[0], self.n_models, 2)) * np.nan\n",
        "        for m in np.arange(len(self.models)):\n",
        "            predm[:, m, :] = self.models[m].predict_proba(X)\n",
        "        return predm.mean(axis=1)\n",
        "\n",
        "\n",
        "def svm_single(data, cv_hyper, config, sample_weight, name, **kwargs):\n",
        "    # Support-vector machine with radial basis function kernel\n",
        "    \n",
        "    hyperparameters= {'C': svm_cspace, 'gamma': svm_gammaspace}\n",
        "    model = hyperparam_search(sk_svm.SVC(kernel='rbf', probability=True),\n",
        "                          hyperparameters,\n",
        "                          use=config.exp_search,\n",
        "                          n_jobs=config.exp_n_kernels,\n",
        "                          cv=cv_hyper,\n",
        "                          scoring=config.exp_optimization_metric,\n",
        "                          n_iter=config.exp_n_iter_rsearch,\n",
        "                          verbose=config.exp_verbose)\n",
        "    model_instance = PredictionModel(model, name, data, config,\n",
        "                                     sample_weight = sample_weight)\n",
        "    return model_instance.output\n",
        "\n",
        "\n",
        "\n",
        "def svm_multi(data, config, group, sample_weight, name, **kwargs):\n",
        "    # Support vector machine ensemble ensemble\n",
        "    ''' Fitting this ensemble is very slow and only recommended on a high performance cluster. The ensemble #\n",
        "    searchers for hyperparameters for each of the 25 base model in the ensemble to increase the variance\n",
        "     across models '''\n",
        "      \n",
        "\n",
        "    resample = \"upsample\" # resample is one of the following [\"none\", \"bootstrap\", \"copy\", \"upsample\"]\n",
        "\n",
        "    if config.exp_do_upsample and (resample==\"upsample\"):\n",
        "       raise ValueError(\"The SVM ensemble upsamples the data already, It is not recommended to upsample another time \\\n",
        "           using the the exp_do_upsample of the Config class.\")\n",
        "       \n",
        "    hyperparameters = {'C': svm_cspace, \"gamma\": svm_gammaspace}\n",
        "    model = SvmMultiObj(config=config, hyperparameters=hyperparameters,\n",
        "                        group=group, resample=resample,\n",
        "                       sample_weight=sample_weight)\n",
        "    \n",
        "    model_instance = PredictionModel(model, name, data, config)\n",
        "    return model_instance.output\n",
        "  \n",
        "class SvmMultiObj(BaseEstimator, ClassifierMixin):\n",
        "       # Train support vector machines in the support vector machine ensemble  \n",
        "    start = time.time()\n",
        "    def __init__(self, config, hyperparameters, group, resample, sample_weight):\n",
        "        self.models = list()\n",
        "        self.n_models = 25 # number of models in the ensemble\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.config = config\n",
        "        self.group = group\n",
        "        self.resample = resample\n",
        "        self.sample_weight = sample_weight\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        for _ in np.arange(self.n_models):\n",
        "\n",
        "            if self.resample == \"bootstrap\":\n",
        "                x_rs, y_rs, group_rs = resample(X, y, self.group, replace=True)\n",
        "            elif self.resample == \"upsample\":\n",
        "                x_rs, y_rs, group_rs = upsample(X, y, \n",
        "                                                group=self.group,\n",
        "                                                costs={0: y.mean(), 1: 1 - y.mean()})\n",
        "            else: x_rs, y_rs, group_rs = X, y, self.group\n",
        "\n",
        "\n",
        "            cv_hyper, cv_fold_vector = create_grouped_folds(y_rs, group_rs, nfolds=5, reps=1)\n",
        "\n",
        "            m = hyperparam_search(sk_svm.SVC(kernel='rbf', probability=True),\n",
        "                              self.hyperparameters,\n",
        "                              use=self.config.exp_search,\n",
        "                              n_jobs=self.config.exp_n_kernels, cv=cv_hyper,\n",
        "                              scoring=self.config.exp_optimization_metric,\n",
        "                              n_iter=self.config.exp_n_iter_rsearch,\n",
        "                              verbose=self.config.exp_verbose)\n",
        "            if self.resample == \"upsample\":\n",
        "                m.fit(x_rs, y_rs)\n",
        "            else:\n",
        "                m.fit(x_rs, y_rs, sample_weight=self.sample_weight)\n",
        "\n",
        "            self.models.append(m)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X, y=None):\n",
        "        predm = np.zeros((X.shape[0], self.n_models, 2)) * np.nan\n",
        "        for m in np.arange(len(self.models)):\n",
        "            predm[:, m, :] = self.models[m].predict_proba(X)\n",
        "        return predm.mean(axis=1)\n",
        "\n",
        "def rmodel(name, costs, config, ident, size):\n",
        "    # Wrapper function to train models in R.\n",
        "    # The actual models in R are trained in the r_run.R script\n",
        "   \n",
        "    if config.r_path is None:\n",
        "        raise ValueError(\"\"\"Please specify the path of R using the Config attribute r_path.\n",
        "     For example, in the experiment script, add the line:\n",
        "     config.r_path = 'C:\\\\Program Files\\\\R\\\\R-3.5.1\\\\bin\\\\x64\\\\Rscript.\"\"\")\n",
        "    \n",
        "    start = time.time()\n",
        "    rfile = 'r_data/out_to_python_' + str(name) + str(ident) + '.csv'\n",
        "    FNULL = open(\"r_data/r_log.txt\", 'w')  # suppress output\n",
        "    \n",
        "    subprocess.check_call([config.r_path, 'scripts\\\\r_run.R',\n",
        "                           str(costs[1]), str(costs[0]), str(ident),\n",
        "                           str(config.exp_n_kernels), str(size), name],\n",
        "                          shell=False, stdout=FNULL, stderr=subprocess.STDOUT)\n",
        "       \n",
        "    while True:    \n",
        "        try:\n",
        "            pred_r = pd.read_csv(rfile, index_col=0)[\"x\"].values\n",
        "            break\n",
        "        except:\n",
        "            pass\n",
        "    out = {\"name\": name,\n",
        "           \"pred\": pred_r,\n",
        "           \"fit\": None,\n",
        "           \"model\": None,\n",
        "           \"hyper_params\": None,\n",
        "           \"shapley\": None,\n",
        "           \"shapley_inter\": None,\n",
        "           \"time\": (time.time() - start)\n",
        "           }\n",
        "    return out"
      ],
      "metadata": {
        "id": "wwcQg9w_2r67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script contains the functions that conduct the cross-validation and forecasting experiments.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import random\n",
        "import xarray as xr\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "\n",
        "\n",
        "def train_and_test(df, config):\n",
        "\n",
        "    \"\"\" Low level experiment function\n",
        "    It samples the training and test data, trains and test the prediction models \n",
        "    (their function are in ml_functions.py)\n",
        "    either with our without the computation of Shapley values\n",
        "    \n",
        "     :param pd.DataFrame df: Data set with an arbitrary number of predictors and the columns\n",
        "        crisis, crisis_id, year, and iso.\n",
        "     :param Config config: Configuration file that specifies the experimental setup\n",
        "    \"\"\"\n",
        "\n",
        "    algo_names = config.exp_algos\n",
        "    nfolds = config.exp_nfolds\n",
        "    hyper_folds = config.exp_hyper_folds\n",
        "    rep_cv = config.exp_rep_cv\n",
        "\n",
        "    X = df.copy()\n",
        "    Y = X['crisis'].values.astype(int)\n",
        "    crisis_id = X['crisis_id'].values.astype(int)\n",
        "    years = X.year.values\n",
        "\n",
        "    X = X.drop(columns=['crisis', 'crisis_id', 'year', 'iso'])\n",
        "    feature_names = X.columns.values\n",
        "    X = np.array(X)\n",
        "\n",
        "    output_ypred = pd.DataFrame(index=np.arange(len(X)), columns=algo_names)\n",
        "\n",
        "    # prepare a list that contains all the results\n",
        "    model_out = {x: list() for x in algo_names}\n",
        "    fits_out = {x: list() for x in algo_names}\n",
        "    time_out = {x: list() for x in algo_names}\n",
        "    params_out = {x: list() for x in algo_names}\n",
        "\n",
        "    if config.exp_do_shapley:\n",
        "        output_shapley = xr.DataArray(np.zeros((len(algo_names),\n",
        "                                                X.shape[0],\n",
        "                                                X.shape[1])) * float(\"nan\"),\n",
        "                                      [('algorithms', algo_names),\n",
        "                                       (\"instances\", np.arange(X.shape[0])),\n",
        "                                       (\"features\", feature_names)])\n",
        "        output_shapley_fnull = pd.DataFrame(index=np.arange(len(X)),\n",
        "                                            columns=algo_names)\n",
        "    else:\n",
        "        output_shapley = None\n",
        "        output_shapley_fnull = None\n",
        "\n",
        "    if config.exp_shapley_interaction:\n",
        "        inter_algos = list(set(algo_names).intersection(set([\"extree\", \"forest\"])))\n",
        "        output_shapley_inter = xr.DataArray(np.zeros((len(inter_algos),\n",
        "                                                X.shape[0],\n",
        "                                                X.shape[1], X.shape[1])) * float(\"nan\"),\n",
        "                                      [('algorithms', inter_algos),\n",
        "                                       (\"instances\", np.arange(X.shape[0])),\n",
        "                                       (\"features1\", feature_names),\n",
        "                                       (\"features2\", feature_names)])\n",
        "    else:\n",
        "        output_shapley_inter = None\n",
        "\n",
        "    results = {'predictions': output_ypred,\n",
        "               \"fits\": fits_out,\n",
        "               'ix_test': [],\n",
        "               'ix_train': [], \n",
        "               'models': model_out,\n",
        "               'parameters': params_out, \"time\": time_out,\n",
        "               'shapley': output_shapley,\n",
        "               \"shapley_fnull\": output_shapley_fnull,\n",
        "               \"data\": [],\n",
        "               'shapley_inter': output_shapley_inter}\n",
        "\n",
        "\n",
        "    if config.exp_year_split is None:\n",
        "        # Create the cross-validation folds\n",
        "        if (config.exp_id == \"none\"):\n",
        "            folds, _ = create_grouped_folds(y=Y, y_group=np.arange(Y.shape[0]),\n",
        "                                          nfolds=nfolds, reps=1)\n",
        "\n",
        "        if(config.exp_id == \"crisis\"):\n",
        "            folds, _ = create_grouped_folds(y=Y, y_group=crisis_id, nfolds=nfolds,\n",
        "                                          reps=1)\n",
        "\n",
        "        if (config.exp_id == \"year_and_crisis\"):\n",
        "            folds, _ = create_grouped_folds(y=Y, y_group=crisis_id, y_group_2=years,\n",
        "                                          nfolds=nfolds, reps=1)\n",
        "        if (config.exp_id == \"year\"):\n",
        "            folds, _ = create_grouped_folds(y=Y, y_group=years, nfolds=nfolds,\n",
        "                                          reps=1)\n",
        "\n",
        "\n",
        "    else:\n",
        "        # If we have a year splitting training and test set:\n",
        "        nfolds = 1\n",
        "\n",
        "    # run through the folds\n",
        "    for f in np.arange(nfolds):\n",
        "        sys.stdout.write('.')\n",
        "\n",
        "        if config.exp_year_split is None:\n",
        "            # obtain training and test set from the previously defined folds\n",
        "            ix_train = list(folds[f][0])\n",
        "            ix_test = list(folds[f][1])\n",
        "        else:\n",
        "            # observations before splitting year are used for training, \n",
        "            # the remaining observations for testing\n",
        "            ix_train = list(np.where(years <= config.exp_year_split)[0])\n",
        "            ix_test = list(np.where(years > config.exp_year_split)[0])\n",
        "\n",
        "        # a random shuffle of the order of observations.\n",
        "        ix_train = np.array(random.sample(ix_train, len(ix_train)))\n",
        "        ix_test = np.array(random.sample(ix_test, len(ix_test)))\n",
        "\n",
        "        if config.exp_bootstrap == \"naive\":\n",
        "            ix_train = np.random.choice(ix_train, size=len(ix_train), replace=True)\n",
        "\n",
        "        if config.exp_bootstrap in [\"up\", \"down\"]:\n",
        "            ix_pos = ix_train[Y[ix_train] == 1]\n",
        "            ix_neg = ix_train[Y[ix_train] == 0]\n",
        "            replacer = False\n",
        "            if config.exp_bootstrap_replace == \"yes\":\n",
        "                replacer = True # whether to sample the minoritty class by replacement as well\n",
        "\n",
        "            if config.exp_bootstrap == \"up\":\n",
        "                if len(ix_neg) > len(ix_pos):\n",
        "                    ix_train = np.concatenate((np.random.choice(ix_neg,\n",
        "                                                                size=len(ix_neg), \n",
        "                                                                replace=replacer),\n",
        "                                               np.random.choice(ix_pos,\n",
        "                                                                size=len(ix_neg),\n",
        "                                                                replace=True)))\n",
        "\n",
        "                if len(ix_pos) > len(ix_neg):\n",
        "                    ix_train = np.concatenate((np.random.choice(ix_pos,\n",
        "                                                                size=len(ix_pos),\n",
        "                                                                replace=replacer),\n",
        "                                               np.random.choice(ix_neg,\n",
        "                                                                size=len(ix_pos), \n",
        "                                                                replace=True)))\n",
        "\n",
        "            if config.exp_bootstrap == \"down\":\n",
        "                if len(ix_neg) > len(ix_pos):\n",
        "                    ix_train = np.concatenate((np.random.choice(ix_pos\n",
        "                                                                , size=len(ix_pos),\n",
        "                                                                replace=replacer),\n",
        "                                               np.random.choice(ix_neg,\n",
        "                                                                size=len(ix_pos),\n",
        "                                                                replace=False)))\n",
        "\n",
        "                if len(ix_pos) > len(ix_neg):\n",
        "                    ix_train = np.concatenate((np.random.choice(ix_neg,\n",
        "                                                                size=len(ix_neg),\n",
        "                                                                replace=replacer),\n",
        "                                               np.random.choice(ix_pos,\n",
        "                                                                size=len(ix_neg), \n",
        "                                                                replace=False)))\n",
        "\n",
        "        results[\"ix_train\"].append(ix_train)\n",
        "        results[\"ix_test\"].append(ix_test)\n",
        "\n",
        "        dat = dict(train_x=X[ix_train, :],\n",
        "                   test_x=X[ix_test,: ],\n",
        "                   train_y=Y[ix_train],\n",
        "                   test_y=Y[ix_test],\n",
        "                   train_crisis_id=crisis_id[ix_train])\n",
        "\n",
        "        # The error costs (false positve, false negative) determine how\n",
        "        # the instances are weighted in the training set\n",
        "        if isinstance(config.exp_error_costs, dict):\n",
        "            class_costs = config.exp_error_costs\n",
        "        elif config.exp_error_costs == \"balanced\": # objects are weighted,\n",
        "            # such that the weighted proportion of objects\n",
        "            #  contribute equally to the training set\n",
        "            class_costs = {0: dat[\"train_y\"].mean(), 1: 1 - dat[\"train_y\"].mean()}\n",
        "        elif config.exp_error_costs == \"0.5\":\n",
        "            class_costs = {0: 0.5, 1: 0.5} # each object has the same weight.\n",
        "\n",
        "        if config.exp_do_upsample: # upsample training set\n",
        "            dat[\"train_x\"], dat[\"train_y\"], \n",
        "            group = upsample(dat[\"train_x\"],\n",
        "                             dat[\"train_y\"],\n",
        "                             group=dat[\"train_crisis_id\"], costs=class_costs)\n",
        "            class_costs_use = {0: 0.5, 1: 0.5}\n",
        "            sample_weight = compute_sample_weight(class_costs_use, dat[\"train_y\"])\n",
        "            cv_hyper, cv_fold_vector = create_grouped_folds(dat['train_y'],\n",
        "                                                          group, nfolds=hyper_folds,\n",
        "                                                          reps=rep_cv)\n",
        "        else: # create folds for the hyperparater search. (Nested cross-validation)\n",
        "            group = dat[\"train_crisis_id\"]\n",
        "            class_costs_use = class_costs\n",
        "            class_weight = weights_from_costs(class_costs_use, dat[\"train_y\"])\n",
        "            sample_weight = compute_sample_weight(class_weight, dat[\"train_y\"])\n",
        "            cv_hyper, cv_fold_vector = create_grouped_folds(dat['train_y'],\n",
        "                                                          dat[\"train_crisis_id\"],\n",
        "                                                          nfolds=hyper_folds,\n",
        "                                                          reps=rep_cv)\n",
        "\n",
        "        # rescale all variables according to the training set\n",
        "        scaler = StandardScaler()\n",
        "        dat['train_x_scaled'] = scaler.fit_transform(dat['train_x'])\n",
        "        dat['test_x_scaled'] = scaler.transform(dat['test_x'])\n",
        "\n",
        "        results[\"data\"].append(dat)\n",
        "\n",
        "        python_algos = [x for x in algo_names if x[0:2] != \"r_\"]\n",
        "        # Train and test PYTHON prediction models \n",
        "        data = {\"trainx\": dat['train_x_scaled'] ,\n",
        "                \"trainy\": dat['train_y'],\n",
        "                \"testx\": dat['test_x_scaled']\n",
        "                }\n",
        "        \n",
        "        for algo in python_algos:\n",
        "            out = globals()[algo](data,\n",
        "                        config=config,\n",
        "                        cv_hyper=cv_hyper,\n",
        "                        group=group,\n",
        "                        sample_weight=sample_weight,\n",
        "                        do_cv = False, name = algo)\n",
        "        \n",
        "            append_results(results, out)\n",
        "\n",
        "\n",
        "        # Some models are trained in R, we call the R script from here.\n",
        "        # The R script loads the  training and test set as a csv,\n",
        "        # We save them here and then save the results as a csv as well.\n",
        "        r_algos = [x for x in algo_names if x[0:2] == \"r_\"]\n",
        "        \n",
        "        if len(r_algos) > 0:\n",
        "            try:\n",
        "                os.makedirs(\"r_data\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            train_r = pd.DataFrame(dat['train_y'],\n",
        "                                   columns=[\"y\"]).join(pd.DataFrame(dat['train_x']))\n",
        "            test_r = pd.DataFrame(dat['test_y'],\n",
        "                                  columns=[\"y\"]).join(pd.DataFrame(dat['test_x']))\n",
        "            ident = np.random.randint(100000000) # random name_suffix as a unique\n",
        "            # identifier for the experiment\n",
        "           \n",
        "            train_r.to_csv('r_data/train_in' + str(ident) + '.csv', sep='\\t')\n",
        "            test_r.to_csv('r_data/test_in' + str(ident) + '.csv', sep='\\t')\n",
        "            pd.Series(cv_fold_vector).to_csv('r_data/cv_fold_vector' \\\n",
        "                     + str(ident) + '.csv', sep='\\t', header = False)\n",
        "               \n",
        "    \n",
        "            for r_algo in r_algos:\n",
        "                out = rmodel(r_algo, class_costs_use, config, ident, 5)\n",
        "                append_results(results, out)\n",
        "                \n",
        "            while True: \n",
        "                try:    \n",
        "                    remove_file('r_data/out_to_python_' + str(r_algo) + str(ident) + '.csv') # remove R file\n",
        "                    remove_file('r_data/train_in' + str(ident) + '.csv')\n",
        "                    remove_file('r_data/test_in' + str(ident) + '.csv')\n",
        "                    remove_file('r_data/cv_fold_vector' + str(ident) + '.csv')\n",
        "                    break\n",
        "                except:\n",
        "                    pass\n",
        "                \n",
        "    return results\n",
        "\n",
        "def append_results(results, add):\n",
        "\n",
        "    \"\"\"Appends the results obtained for a single fold to the previous results\"\"\"\n",
        "    name = add[\"name\"]\n",
        "    ix_test = results[\"ix_test\"][-1] # last element in list\n",
        "\n",
        "    results['predictions'].loc[ix_test, name] = add[\"pred\"]\n",
        "    results['fits'][name].append(add[\"fit\"])\n",
        "\n",
        "    results[\"models\"][name].append(add[\"model\"])\n",
        "    results[\"parameters\"][name].append(add[\"hyper_params\"])\n",
        "    results[\"time\"][name].append(add[\"time\"])\n",
        "    if not add[\"shapley\"] is None:\n",
        "        results[\"shapley\"].loc[name, ix_test, :] = add[\"shapley\"]\n",
        "\n",
        "        if \"shapley_inter\" in add.keys():\n",
        "            if not add[\"shapley_inter\"] is None:\n",
        "                results[\"shapley_inter\"].loc[name, ix_test, :, :] = add[\"shapley_inter\"]"
      ],
      "metadata": {
        "id": "XVQXI-AD2Vyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "import xarray as xr\n",
        "import subprocess\n",
        "import pickle\n",
        "import math\n",
        "import warnings\n",
        "import yaml\n",
        "class Procedure:\n",
        "\n",
        "    def __init__(self, config, df_in=None, file_name=None, name_suffix=\"\", folder=None,\n",
        "                 keep_models=False, keep_data=False, save_data=True, skipExperiment=False):\n",
        "\n",
        "        \"\"\"This is the Procedure class. Here the experiments are conducted and\n",
        "        the results are saved to the hard drive.\n",
        "\n",
        "        :param str Config: Config objects specifying data processing and the experimental setup\n",
        "        :param pd.Data.Frame df_in: The input data. If 'None', the data is generated in this function\n",
        "        :param str file_name: The name given to the output files. If 'None', the name is given by the Config._make_name\n",
        "        :param str name_suffix: Characters that are appended to the file name. This parameter is useful when\n",
        "            you want to add something to the automatically generated file names by Config._make_name.\n",
        "        \n",
        "        :param str folder: The folder where the results are saved. If 'None'\n",
        "            the results are saved in the working directory\n",
        "        \n",
        "        :param Boolean keep_models: Whether the actual models should be saved in pickle files.\n",
        "            This can require substantial disk space and is not recommended\n",
        "        :param Boolean keep_data:  Whether all training and test set partitions should\n",
        "            be saved in the pickle. This can also require substantial space and is not recommended\n",
        "        :param Boolean save_data:  Whether the dataset on which the algorithms are trained\n",
        "            and tested should be written to the hard drive\n",
        "\n",
        "        :param Boolean skipExperiment: Whether the experiment should be skipped\n",
        "            and only the existing pickle files should be aggregated.\n",
        "\n",
        "         \"\"\"\n",
        "        self.collected = False # Indicates whether the results have been collected from the hard drive.\n",
        "        self.name_suffix = name_suffix\n",
        "        self.keep_models = keep_models\n",
        "        self.keep_data = keep_data\n",
        "        self.save_data = save_data\n",
        "        self.config = config\n",
        "\n",
        "        if file_name is None:\n",
        "            self.file_name = config._make_name(self.name_suffix)\n",
        "        else:\n",
        "            self.file_name = file_name\n",
        "        if folder is None:\n",
        "            self.folder = \"results/\" + config._make_name(self.name_suffix) + \"/\"\n",
        "        else:\n",
        "            self.folder = folder\n",
        "        try:\n",
        "            os.makedirs(self.folder)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        with open(self.folder + 'config.yml', 'w') as outfile:\n",
        "            yaml.dump(config, outfile, default_flow_style=False)\n",
        "\n",
        "        # Create dataset\n",
        "        if not df_in is None:\n",
        "            print('Data set given with ')\n",
        "            self.df = df_in.copy()\n",
        "        else:\n",
        "            self.df = create_data(self.config)\n",
        "            print('Data set created with ')\n",
        "\n",
        "        print('    ' + str(np.sum(self.df.crisis.values == 1)) + \" Crises\")\n",
        "        print('    ' + str(np.sum(self.df.crisis.values == 0)) + \" No crises\")\n",
        "        print('    ' + str(self.df.shape[1] - len([\"year\", \"crisis\",\n",
        "                           \"crisis_id\", \"iso\"])) + \" Features\")\n",
        "\n",
        "\n",
        "\n",
        "        self.metrics = [\"auc\", \"accuracy\", \"balanced\", \"tp_rate\", \"fp_rate\",\n",
        "                        \"tp\", \"tn\", \"fp\", \"fn\"] # performance metrics\n",
        "        self.results = list()\n",
        "        if self.save_data:\n",
        "            write_file(self.df, \"data_\" + self.file_name, # save the dataset\n",
        "                      path=self.folder, shorten=False)\n",
        "        self.X = self.df.copy()\n",
        "        self.Y = self.X['crisis'].values.astype(int)\n",
        "        self.X = self.X.drop(columns=['crisis', 'crisis_id', 'year', 'iso'])\n",
        "        self.feature_names  = self.X.columns.values\n",
        "        self.X = np.array(self.X)\n",
        "\n",
        "        # run the experiment\n",
        "        if not skipExperiment:\n",
        "            self._do_experiment()\n",
        "            self._save_pickle(keep_models=self.keep_models, keep_data=self.keep_data)\n",
        "        # write the results to the hard drive\n",
        "        self._write_results()\n",
        "        # write the Shapley values to the hard drive\n",
        "        if self.config.exp_do_shapley:\n",
        "             for m in self.config.exp_algos:\n",
        "                 # we cannot do Shapley decomposition for those models trained in R:\n",
        "                if not m in [\"r_elnet\", \"r_cart\", \"r_c50\"]:\n",
        "                    self._write_shapley(model_name=m)\n",
        "\n",
        "    def _do_experiment(self):\n",
        "        \"\"\"Conduct the experiment\"\"\"\n",
        "        self.results.append(train_and_test(self.df, self.config))\n",
        "        self.config.exp_nrep = len(self.results)\n",
        "\n",
        "\n",
        "    def _collect_results(self):\n",
        "        \"\"\"Read the results from the pickles of the individual iterations saved on the hard drive\n",
        "        and adds results to self.results\"\"\"\n",
        "        if not self.collected:\n",
        "            self.results = []\n",
        "            self.collected = True\n",
        "            if os.path.exists(self.folder):\n",
        "                file_list = os.listdir(self.folder)\n",
        "                pickle_names = [s for s in file_list if \"pickle_\" in s]\n",
        "                pickle_names = [s for s in pickle_names if self.file_name in s]\n",
        "\n",
        "                for p in pickle_names:\n",
        "                    o_old = pickle.load(open(self.folder + p, 'rb'))\n",
        "                    self._add_results(o_old)\n",
        "                    \n",
        "        if not all_same([i[\"predictions\"].shape for i in self.results]):\n",
        "            raise ValueError(\"You try to merge results of different experiments. This is not possible.\")\n",
        "        \n",
        "        if not all_same([set(i[\"predictions\"].columns) for i in self.results]): # results of different sizes are merged\n",
        "                    raise ValueError(\"You try to merge results of different models. This is not possible.\")\n",
        "                \n",
        "    \n",
        "\n",
        "    def _add_results(self, old_object):\n",
        "        # the current results are added to a new object!\n",
        "        if self.file_name != old_object.file_name:\n",
        "            print(\"Experimental configurations do not match\")\n",
        "            return None\n",
        "\n",
        "        self.results = self.results + old_object.results\n",
        "\n",
        "    def _write_results(self, ix=None):\n",
        "        \"\"\"Write the results to the hard drive. This function collects the results from\n",
        "        previous iterations (saved in the pickle files) of this experiment (by calling _collect_results)\n",
        "        and processes them  to produce the csv files.\n",
        "        \n",
        "        :param boolean list ix: Used to subset the observations such that the results\n",
        "            are saved and performance metrics are computed only for these observations.\n",
        "            If it is 'None' all observations are used. \"\"\"\n",
        "\n",
        "\n",
        "        if ix is None: # ix is used\n",
        "            ix_select = [True] * self.df.shape[0] # select all observations\n",
        "        else:\n",
        "            ix_names = self.df[[\"year\", \"iso\"]].apply(lambda x: str(x[0]) + \"_\" + str(x[1]), axis=1).values\n",
        "            ix_select = [x in ix for x in ix_names.tolist()]\n",
        "\n",
        "        self._collect_results()\n",
        "\n",
        "        out_pred = list()\n",
        "        for i in range(len(self.results)):\n",
        "            dout = self.results[i][\"predictions\"].copy()\n",
        "            dout[\"crisis\"] = self.df.crisis\n",
        "            dout[\"year\"] = self.df.year\n",
        "            dout[\"iso\"] = self.df.iso\n",
        "            dout[\"iter\"] = i\n",
        "\n",
        "            # identify fold\n",
        "            folds = [np.where(np.isin(np.arange(len(self.df.crisis)), \n",
        "                                      self.results[i][\"ix_test\"][j]), j + 1, 0) for j in\n",
        "                     np.arange(len(self.results[i][\"ix_test\"]))]\n",
        "\n",
        "            folds = np.vstack(folds).sum(0)\n",
        "\n",
        "            dout[\"fold\"] = folds\n",
        "            out_pred.append(dout)\n",
        "                \n",
        "        pred_all = pd.concat(out_pred)\n",
        "        write_file(pred_all , \"all_pred\" + \"_\" + self.file_name,\n",
        "                  path=self.folder, shorten=False)\n",
        "\n",
        "        # Three types of processing the results of the repeated cross-validation experiment:\n",
        "\n",
        "        # ---- 1 --- #\n",
        "        # Then performance metrics are computed for each iteration across all objects. Then the performance\n",
        "        # metrics are averaged across iterations.\n",
        "        output_metric_across = xr.DataArray(np.zeros((len(self.results), len(self.config.exp_algos),\n",
        "                                                           len(self.metrics))) * float(\"nan\"),\n",
        "                                                 [('iterations', np.arange(len(self.results))),\n",
        "                                                  (\"algorithms\", self.config.exp_algos),\n",
        "                                                  (\"metrics\", self.metrics)])\n",
        "        for r in np.arange(len(self.results)):\n",
        "            res_across_folds = self.results[r]['predictions'].apply(lambda x:\n",
        "                                                    np.array([performance_results(self.df.crisis.values[ix_select],\n",
        "                                                    x[ix_select])[z] for z in self.metrics])).T\n",
        "            res_across_folds.columns = self.metrics\n",
        "            output_metric_across.loc[r, :, :] = res_across_folds\n",
        "\n",
        "        # mean\n",
        "        performance_across_mean = output_metric_across.mean(axis=0).to_pandas()\n",
        "\n",
        "        # standard error\n",
        "        performance_across_se = output_metric_across.std(axis=0).to_pandas() \\\n",
        "        / math.sqrt(float(len(self.results)))\n",
        "\n",
        "        # add the iteration index to the output\n",
        "        iters = [len(self.results)] * performance_across_se.shape[0]\n",
        "        iters = pd.DataFrame({\"iter\": iters}, index=performance_across_se.index.values)\n",
        "\n",
        "        # --- 2 --- #\n",
        "        # The mean predicted value of each object is computed across all replications of the cross-validation.\n",
        "        # Then the performance metrics are calculated based on the mean predicted values.\n",
        "        pred_all_mean = [np.array(out_pred[x][self.config.exp_algos]) for x in range(len(out_pred))]\n",
        "        pred_all_mean = pd.DataFrame(np.stack(pred_all_mean).mean(0))\n",
        "        pred_all_mean.columns = self.config.exp_algos\n",
        "\n",
        "        output_metric_append = pred_all_mean.apply(lambda x:\n",
        "                            np.array([performance_results(self.df.crisis.values[ix_select], x[ix_select])[z]\n",
        "                                                  for z in self.metrics])).T\n",
        "        output_metric_append.columns = self.metrics\n",
        "\n",
        "        # --- 3 --- #\n",
        "        # The performance metrics are computed for each fold in each replication and are then averaged across\n",
        "        # folds and replications.\n",
        "\n",
        "        # This approach is only sensible for the cross-validation experiment. If we split training and test set by year,\n",
        "        # this approach is equivalent to the first type of processing the results\n",
        "        if self.config.exp_year_split is None:\n",
        "            output_metric_fold = xr.DataArray(np.zeros((len(self.results), self.config.exp_nfolds,\n",
        "                                                        len(self.config.exp_algos), len(self.metrics))) * float(\"nan\"),\n",
        "                                                     [('iterations', np.arange(len(self.results))),\n",
        "                                                      ('folds', np.arange(self.config.exp_nfolds)),\n",
        "                                                      (\"algorithms\", self.config.exp_algos),\n",
        "                                                      (\"metrics\", self.metrics)])\n",
        "            for r in np.arange(len(self.results)):\n",
        "                for f in np.arange(self.config.exp_nfolds):\n",
        "                    ix_fold = self.results[r]['ix_test'][f] # get objects of the folds\n",
        "                    ix_fold = set(ix_fold).intersection(set(np.where(np.array(ix_select))[0])) # only investigate those that are on our ix_select\n",
        "                    ix_fold = np.array(list(ix_fold))\n",
        "                    res_in_fold = self.results[r]['predictions'].iloc[ix_fold, :].apply(lambda x:\n",
        "                                    np.array([performance_results(self.df.crisis.values[ix_fold],\n",
        "                                                                  x)[z] for z in self.metrics])).T\n",
        "                    res_in_fold.columns = self.metrics\n",
        "                    output_metric_fold.loc[r, f, :, :] = res_in_fold\n",
        "\n",
        "\n",
        "            # First average across folds in single iteration, then average (and estimate SE) over the replications.\n",
        "            output_metric_fold_mean_folds = output_metric_fold.mean(axis=1)\n",
        "            output_metric_fold_mean = output_metric_fold_mean_folds.mean(axis=0).to_pandas()\n",
        "            output_metric_fold_se = output_metric_fold_mean_folds.std(axis=0).to_pandas()/\\\n",
        "                math.sqrt(float(len(self.results)))\n",
        "\n",
        "        # ix controls the subset selection of year - country pairs\n",
        "        if ix is None:\n",
        "\n",
        "            write_file(pd.concat([performance_across_mean, iters], axis=1),\n",
        "                      \"mean_iter_\" + self.file_name, path=self.folder)\n",
        "            write_file(pd.concat([performance_across_se, iters], axis=1),\n",
        "                      \"se_iter_\" + self.file_name, path=self.folder)\n",
        "            write_file(pd.concat([output_metric_append, iters], axis=1),\n",
        "                      \"mean_append_\" + self.file_name,\n",
        "                      path=self.folder)\n",
        "            if self.config.exp_year_split is None:\n",
        "                write_file(pd.concat([output_metric_fold_mean, iters], axis=1),\n",
        "                          \"mean_fold_\" + self.file_name,\n",
        "                          path=self.folder)\n",
        "                write_file(pd.concat([output_metric_fold_se, iters], axis=1),\n",
        "                          \"se_fold_\" + self.file_name,\n",
        "                          path=self.folder)\n",
        "        else:\n",
        "            write_file(pd.concat([performance_across_mean, iters], axis=1),\n",
        "                      \"mean_iter_ix_\" + self.file_name,\n",
        "                      path=self.folder)\n",
        "            write_file(pd.concat([performance_across_se, iters], axis=1),\n",
        "                      \"se_iter_ix_\" + self.file_name,\n",
        "                      path=self.folder)\n",
        "            write_file(pd.concat([output_metric_append, iters], axis=1),\n",
        "                      \"mean_append_ix_\" + self.file_name,\n",
        "                      path=self.folder)\n",
        "\n",
        "        print(\"After \" + str(len(self.results)) + \" iterations:\")\n",
        "        print(performance_across_mean.round(3))\n",
        "\n",
        "        for algo in self.config.exp_algos:\n",
        "            self._write_hyper_param(algo)\n",
        "\n",
        "    def _write_hyper_param(self, algo):\n",
        "        \"\"\" Writes hyperparameters to the hard drive.\"\"\"\n",
        "        \n",
        "        try:\n",
        "\n",
        "            params = self.results[0][\"parameters\"][algo][0].keys()\n",
        "            out = {}\n",
        "            for p in params:\n",
        "                out[p] = [[z[p] for z in x['parameters'][algo]] for x in self.results]\n",
        "                listed = [x['parameters'][algo] for x in self.results]\n",
        "                listed = [item for sublist in listed for item in sublist]\n",
        "                out[p] = [x[p] for x in listed]\n",
        "                write_file(pd.DataFrame(out), \"hyper_\" + algo + \"_\" + self.file_name,\n",
        "                  path=self.folder, shorten=False)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def _write_shapley(self, model_name=None, **kwargs):\n",
        "        \"\"\" Collects the results of the Shapley experiments from the pickle files\n",
        "        and writes them into csv files.\n",
        "        :param str model_name: Name of the model for which the Shapley values should be collected\n",
        "        \"\"\"\n",
        "        self._collect_results()\n",
        "        do_shap = self.config.exp_do_shapley\n",
        "        if not do_shap:\n",
        "            print(\"No Shapley values found!\")\n",
        "            return None\n",
        "        shap_values = [np.array(x[\"shapley\"].loc[model_name, :, :]) for x in self.results]\n",
        "        nrep = len(shap_values)\n",
        "\n",
        "        shap_values_mean = np.nanmean(np.dstack(shap_values), axis=2) # mean Shapley values across all observations\n",
        "        shap_values_append = np.concatenate(shap_values, axis=0) # Shapley values appended for all replications\n",
        "\n",
        "        pred_matrix = [self.results[x][\"predictions\"][model_name] for x in np.arange(len(self.results))]\n",
        "        # mean predicted value across all replications:\n",
        "        pred_mean = pd.Series(pd.concat((pred_matrix), axis=1).mean(axis=1), name=\"pred\").values  \n",
        "        # predicted values appended for all replications:\n",
        "        pred_append = np.concatenate(pred_matrix, axis=0).astype(float)  \n",
        "\n",
        "        # Prepare a data set with mean Shapley values\n",
        "        shap_out_mean = pd.DataFrame(shap_values_mean, columns=self.feature_names)\n",
        "        shap_out_mean[\"pred\"] = pred_mean\n",
        "        shap_out_mean[\"year\"] = self.df[\"year\"]\n",
        "        shap_out_mean[\"iso\"] = self.df[\"iso\"]\n",
        "        shap_out_mean[\"crisis\"] = self.Y\n",
        "        write_file(shap_out_mean, file_name=\"shapley_mean_\" + model_name \\\n",
        "                  + \"_\" + self.file_name, path=self.folder, shorten=False)\n",
        "\n",
        "        # Prepare a data set with the Shapley values of all replications\n",
        "        shap_out_append = pd.DataFrame(shap_values_append, columns=self.feature_names)\n",
        "        shap_out_append[\"pred\"] = pred_append\n",
        "        shap_out_append[\"year\"] = np.tile(self.df[\"year\"], nrep)\n",
        "        shap_out_append[\"iso\"] = np.tile(self.df[\"iso\"], nrep)\n",
        "        shap_out_append[\"crisis\"] = np.tile(self.Y, nrep)\n",
        "\n",
        "        write_file(shap_out_append, file_name=\"shapley_append_\" + model_name \\\n",
        "                  + \"_\" + self.file_name, path=self.folder,\n",
        "                  shorten=False)\n",
        "\n",
        "    \n",
        "    def _save_pickle(self, file_name=None, keep_models=False, keep_data=False):\n",
        "\n",
        "        \"\"\" Saves the results of the iteration of the experiment into a pickle file\n",
        "        :param Boolean keep_models: Whether the actual models should be saved in pickle files.\n",
        "            This can require substantial disk space and is not recommended.\n",
        "        :param Boolean keep_data:  Whether all training and test set partitions should \n",
        "            be saved in the pickle. This can also require substantial space and is not recommended.\n",
        "        \"\"\"\n",
        "\n",
        "        if file_name is None:\n",
        "            file_name = \"pickle_\" + self.file_name + \"_\" + str(np.random.randint(100000000))\n",
        "\n",
        "        if not keep_models:\n",
        "            for i in np.arange(len(self.results)):\n",
        "                self.results[i][\"models\"] = None\n",
        "        if not keep_data:\n",
        "            for i in np.arange(len(self.results)):\n",
        "                self.results[i][\"data\"] = None\n",
        "\n",
        "        pickle.dump(self, open(self.folder + file_name +\".p\", \"wb\"))"
      ],
      "metadata": {
        "id": "fYU1l7391y0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}